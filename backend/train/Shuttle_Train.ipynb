{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class TrackNetDataset(Dataset):\n",
        "    def __init__(self, frame_paths, indices, heatmaps, img_size):\n",
        "        self.frame_paths = frame_paths\n",
        "        self.indices = indices\n",
        "        self.heatmaps = heatmaps\n",
        "        self.W, self.H = img_size\n",
        "\n",
        "    def _load_frame(self, idx):\n",
        "        frame = cv2.imread(self.frame_paths[idx])\n",
        "        if frame is None:\n",
        "            raise RuntimeError(f\"Missing frame: {self.frame_paths[idx]}\")\n",
        "\n",
        "        frame = cv2.resize(frame, (self.W, self.H))\n",
        "        frame = frame.astype(np.float32) / 255.0\n",
        "        frame = (frame - 0.5) / 0.5\n",
        "        return frame\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.indices[i]\n",
        "\n",
        "        f1 = self._load_frame(idx - 2)\n",
        "        f2 = self._load_frame(idx - 1)\n",
        "        f3 = self._load_frame(idx)\n",
        "\n",
        "        x = np.concatenate([f1, f2, f3], axis=2)\n",
        "        x = torch.from_numpy(x).permute(2, 0, 1)\n",
        "\n",
        "        y = torch.from_numpy(self.heatmaps[i]).unsqueeze(0)\n",
        "\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "epwQGOhILpuA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def generate_heatmap(x, y, H, W, sigma=3):\n",
        "    heatmap = np.zeros((H, W), dtype=np.float32)\n",
        "\n",
        "    if 0 <= x < W and 0 <= y < H:\n",
        "        heatmap[y, x] = 1.0\n",
        "\n",
        "    heatmap = cv2.GaussianBlur(heatmap, (7, 7), sigma)\n",
        "    return heatmap / (heatmap.max() + 1e-6)\n"
      ],
      "metadata": {
        "id": "HuP58etrLy2W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TrackNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TrackNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(9, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.conv5 = nn.Conv2d(256, 1, kernel_size=1)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Input:  (B, 9, H, W)\n",
        "        Output: (B, 1, H, W)\n",
        "        \"\"\"\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.relu(self.conv4(x))\n",
        "        x = self.sigmoid(self.conv5(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ex9p-TKxMbm9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_tracknet(\n",
        "    frame_paths,\n",
        "    labels,\n",
        "    dataset_class,\n",
        "    batch_size=4,\n",
        "    epochs=50,\n",
        "    lr=1e-4,\n",
        "    save_path=\"tracknet.pth\",\n",
        "    device=None\n",
        "):\n",
        "\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # -------------------------\n",
        "    # MODEL\n",
        "    # -------------------------\n",
        "    model = TrackNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # -------------------------\n",
        "    # DATA\n",
        "    # -------------------------\n",
        "    dataset = dataset_class(frame_paths, labels)\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=True if device == \"cuda\" else False\n",
        "    )\n",
        "\n",
        "    # -------------------------\n",
        "    # TRAINING LOOP\n",
        "    # -------------------------\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        print(f\"[Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    # -------------------------\n",
        "    # SAVE MODEL\n",
        "    # -------------------------\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"âœ… TrackNet model saved to: {save_path}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "DoE7ASWHMAQY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LpyreyjxKNSs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "\n",
        "def main_train():\n",
        "    FRAME_DIR = \"frames\"\n",
        "    ANNOTATION_FILE = \"annotations.json\"\n",
        "    INPUT_W, INPUT_H = 960, 540\n",
        "    HEATMAP_SIGMA = 3\n",
        "    BATCH_SIZE = 8\n",
        "    EPOCHS = 50\n",
        "    LR = 1e-4\n",
        "    VAL_SPLIT = 0.2\n",
        "    MODEL_PATH = \"tracknet.pth\"\n",
        "\n",
        "    frame_paths = sorted([\n",
        "        os.path.join(FRAME_DIR, f)\n",
        "        for f in os.listdir(FRAME_DIR)\n",
        "        if f.endswith(\".jpg\")\n",
        "    ])\n",
        "\n",
        "    print(\"Frame_paths loaded\")\n",
        "\n",
        "    # Load annotations\n",
        "    with open(ANNOTATION_FILE) as f:\n",
        "        ann = json.load(f)\n",
        "\n",
        "    print(\"Annotations loaded\")\n",
        "    indices, heatmaps = [], []\n",
        "    for k in sorted(ann.keys(), key=int):\n",
        "        idx = int(k)\n",
        "        if idx >= 2:\n",
        "            x, y = ann[k]\n",
        "            indices.append(idx)\n",
        "            heatmaps.append(\n",
        "                generate_heatmap(x, y, INPUT_W, INPUT_H, HEATMAP_SIGMA)\n",
        "            )\n",
        "\n",
        "    heatmaps = np.array(heatmaps, dtype=np.float32)\n",
        "    print(\"Heatmaps generated\")\n",
        "\n",
        "    dataset = TrackNetDataset(\n",
        "        frame_paths, indices, heatmaps, (INPUT_W, INPUT_H)\n",
        "    )\n",
        "\n",
        "    print(\"Dataset created\")\n",
        "\n",
        "    # Train/val split\n",
        "    val_len = int(len(dataset) * VAL_SPLIT)\n",
        "    train_len = len(dataset) - val_len\n",
        "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "    print(\"Data loaders created\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(\"Device: \", device)\n",
        "\n",
        "    # Model\n",
        "    model = TrackNet().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    print(\"Model created\")\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    print(\"Best val: \", best_val)\n",
        "\n",
        "    # ---------------- TRAIN LOOP ----------------\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            pred = model(x)\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                val_loss += criterion(model(x), y).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        print(f\"[{epoch+1:02d}] Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            print(\"âœ… Saved best model\")\n",
        "\n",
        "    print(\"ðŸŽ¯ Training complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "grapJRATLkys",
        "outputId": "aaf2b3db-c288-417b-c128-a6a854b4b631"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'frames'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3407262384.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2606907556.py\u001b[0m in \u001b[0;36mmain_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     frame_paths = sorted([\n\u001b[1;32m     27\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRAME_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFRAME_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     ])\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'frames'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGvJVKsIR33B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}